# 网站搜索引擎项目Ai助手帮助文档

## 概述
这是一个使用现代技术栈构建的网站搜索引擎项目。

## 技术架构
* 前端: Next.js (TypeScript语法)
* 后端: Go语言
* 爬虫: Go语言
* 数据存储:
  * Redis (缓存)
  * PostgreSQL (关系型数据库)

## 项目结构
```
Searchsite
|
├─backend 后端文件夹
├─crawler 爬虫文件夹
├─crawler_backend 爬虫后端文件夹
├─data docker数据库映射
│  ├─postgresql
│  └─redis
└─frontend 前端界面
```

## 总体逻辑

该项目旨在构建一个高效且可扩展的网站搜索引擎，核心目标是为用户提供精准的搜索结果，并且通过爬虫定期获取和更新网站内容。

### 1. 用户搜索流程

1. 通过前端界面输入关键词
2. 前端将关键词通过 HTTP 请求（如 POST）发送至后端 API
3. 后端接收到请求后，从数据库中查找相关的索引数据，返回给前端
4. 如果没有则返回"没有搜到诶~要不换个关键词试试",网站链接需要网站管理员或者该项目运营添加

### 2. 爬虫系统架构

#### 2.1 基础爬虫流程

1. 后端根据前端的请求，将待爬取的链接存储到任务队列中
2. 爬虫从任务队列中获取需要爬取的链接，开始执行爬虫任务
3. 爬虫根据任务配置和爬取策略（如遵循 robots.txt 和设置合法的 User-Agent），访问目标网站并抓取内容
4. 爬取的数据经过处理后，将结果存储到数据库或缓存中，以便快速查询
5. 如果爬取过程中遇到无法访问的链接（如 301、502 错误等），爬虫会记录这些链接，并通过后端反馈给前端网站管理员界面

#### 2.2 分布式爬虫架构

1. 爬虫注册与管理：
   * 每个爬虫实例首次启动时需要向爬虫后端注册
   * 注册时分配唯一的 UUID，避免 IP 端口冲突
   * 爬虫需要提供轮询状态路由，用于健康检查

2. 爬虫后端职责：
   * 维护可用爬虫列表及其状态（在线/离线）
   * 记录每个爬虫的连接信息
   * 实施健康检查机制，自动剔除不健康的爬虫实例
   * 负责任务分配策略和调度

3. 完整工作流程：
   * 网站管理员通过管理界面提交页面给后端
   * 后端将爬取请求转发给爬虫后端
   * 爬虫后端根据任务分配策略选择合适的爬虫执行任务
   * 爬虫执行爬取并返回结果给爬虫后端
   * 爬虫后端汇总结果并返回给网页后端
   * 后端将链接信息写入数据库

### 3. 数据存储与更新

1. 爬虫成功抓取的网页内容将被存储在 PostgreSQL 数据库中，确保数据的持久性和查询效率
2. 数据中的相关信息（如页面链接、标题、内容摘要等）会被索引，便于快速检索
3. 为了提高查询速度和缓存效率，所有常用的查询结果将缓存到 Redis 中
4. 爬虫会定期更新已经爬取的内容，以确保搜索结果的时效性和准确性

### 4. 前端与后端交互

1. 前端使用 Next.js 作为框架，提供一个简洁且响应式的用户界面
2. 用户的搜索请求通过前端界面发送至后端，后端根据用户的输入返回相关的搜索结果
3. 在获取不到数据时，后端会启动爬虫去抓取相关内容，并将结果反馈给用户
4. 前端展示的搜索结果会根据后端返回的数据进行渲染，确保用户获得最新的搜索信息

### 5. 错误处理与反馈机制

1. 在爬取过程中，遇到任何问题（如 HTTP 错误、网络问题等），爬虫会记录问题并反馈给后端
2. 后端会根据错误类型（如 301 重定向、502 错误等）进行处理，确保爬虫任务不会重复执行
3. 错误信息会返回给前端，提醒用户该任务当前无法完成，并建议稍后再试

### 6. 扩展性

1. 为了应对未来可能增加的爬取任务，系统会通过分布式爬虫架构进行水平扩展，支持更多的爬虫节点进行并行抓取任务
2. 后端和爬虫系统采用 Go 语言编写，充分利用多线程机制和内存优化技术，确保低成本、高效率地处理大量爬虫任务
3. 数据库和缓存系统也具备高可用性和扩展性，能够适应大规模的数据存储和高并发查询需求

## 项目规划

### 前端结构

项目前端包含三个文件夹：

* administrator - 网站运营后台（供这个项目的管理员使用）
* user - 用户网站（供普通用户使用）
* Manage - 网站管理员（供网站管理员使用，以便提交索引链接）

前端的详细布局设计、样式规范、组件结构以及初始化步骤请参考 `./frontend/UI.md`。

### 后端爬虫规范

1. 必须遵守 robots.txt 规范
2. 必须使用合法的 User-Agent 头
3. 确保前端使用POST请求时后端能及时回应

### 用户需求处理流程

1. 当用户请求帮助完成任务时：
   * 如果任务中包含明确的"任务规划"：
     * 严格按给定的规划执行
   * 如果没有提到"任务规划"：
     * 先向用户提问确认需求
     * 得到回复后再执行
   * 如果用户让AI自行规划：
     * 首先提出执行规划和所需工具
     * 说明工具的使用方法
     * 确保规划合理后才列出详细计划

2. 请勿修改依赖文件：
   * （权重高）
   * 请勿直接修改依赖文件，应使用对应包管理工具（如 Go Modules、npm）进行管理

3. 如果用户提出让AI助手自主规划并完成任务：
   * 请确保规划合理且符合用户需求以及逻辑正确的情况下编写代码

## 项目标准
* 不需要生成任何示例（例如示例网页等）
* 在网页中要实现响应式布局以及简约的UI布局（例如：使用Bootstrap、Material UI、Tailwind CSS等）
* 首页搜索框应居中显示，风格应统一、简约
* 数据库使用Redis和PostgreSQL，现使用docker部署数据库
* 不要包含任何测试用例，现供直接投入使用
* 确保后续不会留下安全漏洞以及后门
* 在编写过程中定期更新后端/前端的README.md文件，确保下一个ai助理能继续工作

---
在自动代理完成任务时，请定期阅读该tips.md文件，以获取更新规范以及避免上下文丢失。

如果不了解或者重启对话后导致的不了解项目，请阅读前端/后端的README.md文件。要保持定期更新README.md文件，以便下一个ai助理能继续工作.
